{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3399518c",
   "metadata": {},
   "source": [
    "1. Step\n",
    "- load the dataset as pandas dataframe and extract the edges between nodes and their capacity over all the lanes in one direction together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def0359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Overall_capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1371</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "      <td>3200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2402</td>\n",
       "      <td>2200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1875</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1880</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11135</th>\n",
       "      <td>4806</td>\n",
       "      <td>1495</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11136</th>\n",
       "      <td>4806</td>\n",
       "      <td>3606</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11137</th>\n",
       "      <td>4806</td>\n",
       "      <td>415</td>\n",
       "      <td>9000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11138</th>\n",
       "      <td>4807</td>\n",
       "      <td>1433</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11139</th>\n",
       "      <td>4807</td>\n",
       "      <td>1434</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11140 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       From    To  Overall_capacity\n",
       "0         1  1371            1800.0\n",
       "1         2  2012            3200.0\n",
       "2         3  2402            2200.0\n",
       "3         4  1875             800.0\n",
       "4         5  1880             800.0\n",
       "...     ...   ...               ...\n",
       "11135  4806  1495             600.0\n",
       "11136  4806  3606             600.0\n",
       "11137  4806   415            9000.0\n",
       "11138  4807  1433             800.0\n",
       "11139  4807  1434             400.0\n",
       "\n",
       "[11140 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "df = pd.read_csv(\"Analysis/GoldCoast.csv\")\n",
    "df_edges = df[[\"From\",\"To\", \"Overall_capacity\"]]\n",
    "df_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73579ad",
   "metadata": {},
   "source": [
    "2. Step\n",
    "- load the dataframe as edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebbc1a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4783, 11140)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.from_pandas_edgelist(\n",
    "    df,\n",
    "    source=\"From\",\n",
    "    target=\"To\",\n",
    "    edge_attr=[\"Overall_capacity\"],\n",
    "    create_using=nx.DiGraph()\n",
    ")\n",
    "Nodes = G.number_of_nodes()\n",
    "Edges = G.number_of_edges()\n",
    "Nodes, Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfb5942",
   "metadata": {},
   "source": [
    "3. Step\n",
    "- load the dataframe from a different file that's containing coordinates of the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7e918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = pd.read_csv('nodes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca4f44",
   "metadata": {},
   "source": [
    "4. Step\n",
    "- extracting candidate pairs of nodes (possible future edges) that are located maximum 2 steps away \n",
    "- creating a balanced labeled data set of existing edges and candidate pair (no edges)\n",
    "- feature extraction \n",
    "- creating a dataframe of the labeled dataset of node pairs and their features\n",
    "- training a random forest classifier on a masked portion of edges ensuring integrity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2822f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked 2228 edges out of 11140\n",
      "Performance on masked edges:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.89      1513\n",
      "           1       0.99      0.83      0.91      2228\n",
      "\n",
      "    accuracy                           0.90      3741\n",
      "   macro avg       0.90      0.91      0.90      3741\n",
      "weighted avg       0.91      0.90      0.90      3741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ------------------- MASK EDGES -------------------\n",
    "def mask_edges(G, mask_frac=0.1, seed=42):\n",
    "    \"\"\"Randomly remove a fraction of edges to use as a test set\"\"\"\n",
    "    random.seed(seed)\n",
    "    edges = list(G.edges())\n",
    "    n_mask = int(len(edges) * mask_frac)\n",
    "    masked_edges = random.sample(edges, n_mask)\n",
    "    G_train = G.copy()\n",
    "    G_train.remove_edges_from(masked_edges)\n",
    "    return G_train, masked_edges\n",
    "\n",
    "# ------------------- REACHABLE NODES CACHE -------------------\n",
    "_REACHABLE_CACHE = {}\n",
    "\n",
    "def compute_reachable_nodes(G, max_distance=2, cache_key=None):\n",
    "    \"\"\"Compute reachable nodes once and cache results\"\"\"\n",
    "    if cache_key and cache_key in _REACHABLE_CACHE:\n",
    "        return _REACHABLE_CACHE[cache_key]\n",
    "    \n",
    "    reachable = {u: set() for u in G.nodes()}\n",
    "    for u in G.nodes():\n",
    "        visited = {u}\n",
    "        frontier = deque([(u, 0)])\n",
    "        while frontier:\n",
    "            current, dist = frontier.popleft()\n",
    "            if dist == max_distance: \n",
    "                continue\n",
    "            for nxt in G.successors(current):\n",
    "                if nxt not in visited:\n",
    "                    visited.add(nxt)\n",
    "                    frontier.append((nxt, dist + 1))\n",
    "                    if nxt != u:\n",
    "                        reachable[u].add(nxt)\n",
    "    \n",
    "    if cache_key:\n",
    "        _REACHABLE_CACHE[cache_key] = reachable\n",
    "    \n",
    "    return reachable\n",
    "\n",
    "# ------------------- HARD NEGATIVE DATASET -------------------\n",
    "def create_labeled_dataset_with_hard_negatives(G, cor, positives, max_distance=2, \n",
    "                                               negatives_per_positive=1, max_euclid_dist=0.005,\n",
    "                                               reachable_dict=None):\n",
    "    \"\"\"\n",
    "    G: training graph\n",
    "    positives: list of (u,v) edges to include\n",
    "    reachable_dict: OPTIONAL precomputed reachable nodes (saves computation)\n",
    "    Returns: labeled dataset with realistic negatives\n",
    "    \"\"\"\n",
    "    positions = {row['node']: (row['x'], row['y']) for _, row in cor.iterrows()}\n",
    "    dataset = []\n",
    "\n",
    "    # Use precomputed reachable dict or compute new one\n",
    "    if reachable_dict is not None:\n",
    "        reachable = reachable_dict\n",
    "    else:\n",
    "        reachable = compute_reachable_nodes(G, max_distance)\n",
    "\n",
    "    # Precompute in-degrees and existing edges for O(1) lookups\n",
    "    in_degrees = {node: G.in_degree(node) for node in G.nodes()}\n",
    "    existing_edges = set(G.edges())\n",
    "    \n",
    "    for u, v_pos in positives:\n",
    "        dataset.append((u, v_pos, 1))\n",
    "        \n",
    "        if negatives_per_positive > 0:\n",
    "            candidates = []\n",
    "            x_u, y_u = positions[u]\n",
    "            target_degree = in_degrees[v_pos]\n",
    "            \n",
    "            # Filter candidates efficiently\n",
    "            for v in reachable[u]:\n",
    "                if (u, v) not in existing_edges:\n",
    "                    x_v, y_v = positions[v]\n",
    "                    euclid_dist = np.sqrt((x_u - x_v)**2 + (y_u - y_v)**2)\n",
    "                    if euclid_dist <= max_euclid_dist:\n",
    "                        degree_diff = abs(in_degrees[v] - target_degree)\n",
    "                        candidates.append((v, degree_diff))\n",
    "            \n",
    "            if candidates:\n",
    "                candidates.sort(key=lambda x: x[1])\n",
    "                chosen = [v for v, _ in candidates[:negatives_per_positive]]\n",
    "                dataset.extend([(u, v_neg, 0) for v_neg in chosen])\n",
    "\n",
    "    random.shuffle(dataset)\n",
    "    return dataset\n",
    "\n",
    "# ------------------- OPTIMIZED FEATURE EXTRACTION -------------------\n",
    "class FeatureExtractor:\n",
    "    \"\"\"Optimized feature extraction with caching\"\"\"\n",
    "    def __init__(self, G, cor):\n",
    "        self.G = G\n",
    "        self.cor = cor\n",
    "        self.positions = {row['node']: (row['x'], row['y']) for _, row in cor.iterrows()}\n",
    "        self._cache = {}\n",
    "        \n",
    "    def extract_features_batch(self, node_pairs):\n",
    "        \"\"\"Extract features for multiple pairs efficiently\"\"\"\n",
    "        features = []\n",
    "        for u, v, label in node_pairs:\n",
    "            # Use caching for expensive computations\n",
    "            cache_key = (u, v)\n",
    "            if cache_key in self._cache:\n",
    "                feat = self._cache[cache_key].copy()\n",
    "                feat.update({'node_u': u, 'node_v': v, 'label': label})\n",
    "            else:\n",
    "                feat = self._extract_features_single(u, v, label)\n",
    "                self._cache[cache_key] = {k: v for k, v in feat.items() \n",
    "                                         if k not in ['node_u', 'node_v', 'label']}\n",
    "            features.append(feat)\n",
    "        return pd.DataFrame(features)\n",
    "    \n",
    "    def _extract_features_single(self, u, v, label):\n",
    "        \"\"\"Extract features for a single pair\"\"\"\n",
    "        preds = set(self.G.predecessors(u)) & set(self.G.predecessors(v))\n",
    "        succs = set(self.G.successors(u)) & set(self.G.successors(v))\n",
    "        feat = {\n",
    "            'node_u': u, 'node_v': v, 'label': label,\n",
    "            'common_predecessors': len(preds),\n",
    "            'common_successors': len(succs),\n",
    "            'out_in_degree_product': self.G.out_degree(u) * self.G.in_degree(v),\n",
    "            'directional_adamic_adar': self._directed_adamic_adar(u, v, succs),\n",
    "            'directional_resource_allocation': self._directed_resource_allocation(u, v, succs),\n",
    "            'euclidian_distance': self._extract_euclid_dist(u, v)\n",
    "        }\n",
    "        feat.update(self._extract_capacity_features(u, v))\n",
    "        return feat\n",
    "    \n",
    "    def _directed_adamic_adar(self, u, v, succs=None):\n",
    "        \"\"\"Optimized adamic adar calculation\"\"\"\n",
    "        if succs is None:\n",
    "            succs = set(self.G.successors(u)) & set(self.G.successors(v))\n",
    "        score = 0\n",
    "        for w in succs:\n",
    "            deg = self.G.in_degree(w)\n",
    "            if deg > 1:\n",
    "                score += 1 / np.log(deg)\n",
    "        return score\n",
    "    \n",
    "    def _directed_resource_allocation(self, u, v, succs=None):\n",
    "        \"\"\"Optimized resource allocation calculation\"\"\"\n",
    "        if succs is None:\n",
    "            succs = set(self.G.successors(u)) & set(self.G.successors(v))\n",
    "        score = 0\n",
    "        for w in succs:\n",
    "            deg = self.G.in_degree(w)\n",
    "            if deg > 0:\n",
    "                score += 1 / deg\n",
    "        return score\n",
    "    \n",
    "    def _extract_euclid_dist(self, u, v):\n",
    "        \"\"\"Fast Euclidean distance using precomputed positions\"\"\"\n",
    "        x_u, y_u = self.positions[u]\n",
    "        x_v, y_v = self.positions[v]\n",
    "        return np.sqrt((x_u - x_v)**2 + (y_u - y_v)**2)\n",
    "    \n",
    "    def _extract_capacity_features(self, u, v):\n",
    "        \"\"\"Extract capacity features with caching\"\"\"\n",
    "        def get_capacities(node, direction='out'):\n",
    "            if direction == 'out':\n",
    "                return [self.G[node][n].get('Overall_capacity', 0) for n in self.G.successors(node)]\n",
    "            else:\n",
    "                return [self.G[n][node].get('Overall_capacity', 0) for n in self.G.predecessors(node)]\n",
    "        \n",
    "        u_out = get_capacities(u, 'out')\n",
    "        u_in = get_capacities(u, 'in')\n",
    "        v_out = get_capacities(v, 'out')\n",
    "        v_in = get_capacities(v, 'in')\n",
    "        \n",
    "        return {\n",
    "            'avg_out_capacity_u': np.mean(u_out) if u_out else 0,\n",
    "            'avg_in_capacity_u': np.mean(u_in) if u_in else 0,\n",
    "            'avg_out_capacity_v': np.mean(v_out) if v_out else 0,\n",
    "            'avg_in_capacity_v': np.mean(v_in) if v_in else 0,\n",
    "            'min_out_capacity_u': min(u_out) if u_out else 0,\n",
    "            'min_in_capacity_v': min(v_in) if v_in else 0\n",
    "        }\n",
    "\n",
    "# ------------------- PIPELINE -------------------\n",
    "# 1️⃣ Mask edges for testing\n",
    "G_train, masked_edges = mask_edges(G, mask_frac=0.2)\n",
    "print(f\"Masked {len(masked_edges)} edges out of {G.number_of_edges()}\")\n",
    "\n",
    "# 2️⃣ Precompute reachable nodes ONCE\n",
    "reachable = compute_reachable_nodes(G_train, max_distance=2, cache_key='train')\n",
    "\n",
    "# 3️⃣ Prepare datasets using precomputed reachable nodes\n",
    "train_dataset = create_labeled_dataset_with_hard_negatives(\n",
    "    G_train, cor, list(G_train.edges()), reachable_dict=reachable\n",
    ")\n",
    "test_dataset = create_labeled_dataset_with_hard_negatives(\n",
    "    G_train, cor, masked_edges, reachable_dict=reachable\n",
    ")\n",
    "\n",
    "# 4️⃣ Extract features using optimized extractor\n",
    "feature_extractor = FeatureExtractor(G_train, cor)\n",
    "X_train = feature_extractor.extract_features_batch(train_dataset)\n",
    "X_test = feature_extractor.extract_features_batch(test_dataset)\n",
    "\n",
    "feature_cols = [c for c in X_train.columns if c not in ['node_u', 'node_v', 'label']]\n",
    "y_train = X_train['label']\n",
    "X_train = X_train[feature_cols]\n",
    "y_test = X_test['label']\n",
    "X_test = X_test[feature_cols]\n",
    "\n",
    "# 5️⃣ Train Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 6️⃣ Evaluate on masked edges (true test set)\n",
    "y_hat = rf_model.predict(X_test)\n",
    "print(\"Performance on masked edges:\")\n",
    "print(classification_report(y_test, y_hat))\n",
    "\n",
    "# Store the reachable dict for use in prediction\n",
    "REACHABLE_FOR_PREDICTION = reachable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2932d8cb",
   "metadata": {},
   "source": [
    "5. Step\n",
    "- assessment of the non-edge node pairs\n",
    "- where should there be an existing edge, based on the patterns that random forest classifier learned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e767ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 recommended new directed roads:\n",
      "      from_node  to_node  probability\n",
      "4437       1291     2134         0.99\n",
      "9319       4064     4060         0.99\n",
      "8902       3955     3954         0.98\n",
      "6701       4056     4057         0.98\n",
      "1397       2338     1714         0.98\n",
      "8057       2134     1291         0.98\n",
      "9409       4414     4411         0.98\n",
      "9406       4406     4413         0.97\n",
      "9388       4360     4357         0.97\n",
      "8701       2910     2876         0.97\n",
      "6848       4212     4211         0.96\n",
      "5780       4114     4110         0.94\n",
      "4287       1250     2569         0.94\n",
      "7167       3949     4134         0.94\n",
      "7162       3921     4134         0.94\n",
      "8674       2855     2856         0.93\n",
      "9361       4164     2968         0.93\n",
      "8741       3496     4365         0.93\n",
      "8697       2879     4398         0.92\n",
      "8687       2909     4396         0.92\n"
     ]
    }
   ],
   "source": [
    "def predict_new_links_directed(G, trained_model, cor, feature_columns, \n",
    "                               max_distance=2, max_euclid_dist=0.02, \n",
    "                               reachable_dict=None):\n",
    "    \"\"\"\n",
    "    Predict the probability that a directed edge should exist for candidate pairs.\n",
    "    \n",
    "    Parameters:\n",
    "    - G: the graph (use full graph or training graph)\n",
    "    - trained_model: your trained RF model\n",
    "    - cor: DataFrame with node coordinates ['node','x','y']\n",
    "    - feature_columns: columns used for training\n",
    "    - max_distance: max BFS distance to generate candidate pairs\n",
    "    - max_euclid_dist: max Euclidean distance for candidate pairs\n",
    "    - reachable_dict: OPTIONAL precomputed reachable nodes (REQUIRED for efficiency!)\n",
    "    \"\"\"\n",
    "    # Step 1: Generate candidate pairs\n",
    "    positions = {row['node']: (row['x'], row['y']) for _, row in cor.iterrows()}\n",
    "    candidate_pairs = []\n",
    "    \n",
    "    # Use precomputed reachable dict or compute new one\n",
    "    if reachable_dict is not None:\n",
    "        reachable = reachable_dict\n",
    "    else:\n",
    "        print(\"Warning: Computing reachable nodes from scratch - pass reachable_dict for efficiency\")\n",
    "        reachable = compute_reachable_nodes(G, max_distance, cache_key='predict')\n",
    "    \n",
    "    # Create set of existing edges for O(1) lookup\n",
    "    existing_edges = set(G.edges())\n",
    "    \n",
    "    # Generate candidate pairs efficiently\n",
    "    for u in G.nodes():\n",
    "        x_u, y_u = positions[u]\n",
    "        for v in reachable[u]:\n",
    "            if (u, v) not in existing_edges:\n",
    "                # Apply Euclidean distance limit\n",
    "                x_v, y_v = positions[v]\n",
    "                euclid_dist = np.sqrt((x_u - x_v)**2 + (y_u - y_v)**2)\n",
    "                if euclid_dist <= max_euclid_dist:\n",
    "                    candidate_pairs.append((u, v, -1))  # -1 label for unknown\n",
    "    \n",
    "    if not candidate_pairs:\n",
    "        print(\"No candidate pairs found with given constraints\")\n",
    "        return pd.DataFrame(columns=['from_node', 'to_node', 'probability'])\n",
    "    \n",
    "    # Step 2: Extract features\n",
    "    feature_extractor = FeatureExtractor(G, cor)\n",
    "    X_candidates = feature_extractor.extract_features_batch(candidate_pairs)\n",
    "    X_input = X_candidates[feature_columns]\n",
    "    \n",
    "    # Step 3: Predict probabilities\n",
    "    probabilities = trained_model.predict_proba(X_input)[:, 1]\n",
    "    \n",
    "    # Step 4: Return DataFrame sorted by probability\n",
    "    results = pd.DataFrame({\n",
    "        'from_node': [u for u, v, _ in candidate_pairs],\n",
    "        'to_node': [v for u, v, _ in candidate_pairs],\n",
    "        'probability': probabilities\n",
    "    })\n",
    "    \n",
    "    return results.sort_values('probability', ascending=False)\n",
    "\n",
    "# ------------------- USAGE -------------------\n",
    "# Use the reachable dict computed during training\n",
    "best_new_links = predict_new_links_directed(\n",
    "    G, rf_model, cor, feature_cols, \n",
    "    max_distance=2, \n",
    "    max_euclid_dist=0.005,\n",
    "    reachable_dict=REACHABLE_FOR_PREDICTION  \n",
    ")\n",
    "\n",
    "print(\"Top 20 recommended new directed roads:\")\n",
    "print(best_new_links.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
